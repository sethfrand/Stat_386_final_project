{"title":"Technical Report","markdown":{"yaml":{"title":"Technical Report","jupyter":"python3"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nThis project analyzes Utah residential housing listings in several cities in Salt Lake County and Utah counties to explore, build, and evaluate predictive models for house `price`.\n\nThe motivation for this project is to provide data-driven guidance for buyers, sellers, and local planners by identifying key predictors of sale price and producing models that balance predictive accuracy and interpretability.\n\nSome key goals of this project were (1) to produce clear exploratory analyses that reveal relationships between `price` and common housing attributes; (2) to fit defensible regression models (i.e. best-subsets by AIC and a LASSO-regularized model) and compare them using cross-validated PMSE; and (3) to document reproducible code and a small interactive Streamlit app for sharing results.\n\n\n## Data Source and Methodology\n\n1. Data acquisition:\n\n- Raw listings were collected from UtahRealEstate.com with the repository's scraping scripts. The primary ingestion function used in this report is `data_no_scape()` which returns the raw DataFrame used for downstream processing.\n\n2. Cleaning pipeline:\n\n- The cleaning pipeline performs the following steps: removing obvious duplicates, dropping invalid or malformed entries, and standardizing numeric columns (e.g. beds, baths, sqft). For purposes of analysis, we dropped the original `address` and `mls` fields.\n\n3. Analysis workflow:\n\n- Exploratory data analysis involved  visual checks (scatterplots and boxplots) to inspect relationships between `price` and candidate predictors and to assess outliers and heterogeneity across selected cities.\n- Model selection involved exhaustive best-subsets regression evaluated by AIC to identify an interpretable model, and LASSO (with cross-validated penalty) to perform automated variable selection and shrinkage. Models were fit with `statsmodels` and model summaries were constructed with `patsy`.\n- Model assessment: 5-fold cross-validation is used to estimate the predictive mean squared error (PMSE) for competing models.\n\n4. Tooling and reproducibility:\n\n- Primary libraries: `pandas`, `numpy`, `matplotlib`, `seaborn`, `statsmodels`, `patsy`, `scikit-learn`.\n- Project environment and packaging: see `pyproject.toml`\n\n\n## EDA\n\n```{python}\n#| include: false\nimport pandas as pd\nfrom utah_housing_stat386.cleaning import data_no_scape, cleaned_static_data, clean_housing_data, remove_duplicates, remove_invalid_entries\nimport re\n\ndf_raw = data_no_scape()\ndf_clean2 = clean_housing_data(df_raw)\ndf_clean2 = remove_duplicates(df_clean2)\ndf_clean2 = remove_invalid_entries(df_clean2)\ndf = df_clean2.copy()\naddress_list = df['address'].tolist()\npattern = r\"UT \\d{5}\"\nzipcode_list = []\nfor address in address_list:\n    zipcode_list.append(re.search(pattern, address).group()[3:])\ndf['zipcode'] = zipcode_list\ndf = df.drop(columns=['address', 'mls', 'zipcode'])\n```\n```{python}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Create a 2x2 figure with 4 subplots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfig.suptitle('EDA: Price vs Selected Variables', fontsize=16, fontweight='bold')\n\n# Plot 1 (top-left): Scatterplot - price vs bedrooms (or sqft, year_built, etc.)\naxes[0, 0].scatter(df['beds'], df['price'], alpha=0.5, s=50, color='steelblue')\naxes[0, 0].set_xlabel('Bedrooms', fontsize=11)\naxes[0, 0].set_ylabel('Price ($)', fontsize=11)\naxes[0, 0].set_title('Price vs Bedrooms', fontweight='bold')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_xlim(0, 10)\naxes[0, 0].set_ylim(0, 3_000_000)\n\n# Plot 2 (top-right): Scatterplot - price vs bathrooms (or sqft, lot_size, etc.)\naxes[0, 1].scatter(df['baths'], df['price'], alpha=0.5, s=50, color='coral')\naxes[0, 1].set_xlabel('Bathrooms', fontsize=11)\naxes[0, 1].set_ylabel('Price ($)', fontsize=11)\naxes[0, 1].set_title('Price vs Bathrooms', fontweight='bold')\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xlim(0, 10)\naxes[0, 1].set_ylim(0, 3_000_000)\n\n# Plot 3 (bottom-left): Boxplot - price by garage (categorical)\naxes[1, 0].scatter(df['sqft'], df['price'], alpha=0.5, s=50)\naxes[1, 0].set_xlabel('Square Feet', fontsize=11)\naxes[1, 0].set_ylabel('Price ($)', fontsize=11)\naxes[1, 0].set_title('Price vs Square Footage', fontweight='bold')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_xlim(0, 15_000)\naxes[1, 0].set_ylim(0, 4_000_000)\n\n# Plot 4 (bottom-right): Boxplot - price by city (categorical)\nsub_df = df[df['city'].isin(['lindon', 'orem', 'provo', 'spanish-fork'])]\nsub_df.boxplot(column='price', by='city', ax=axes[1, 1])\naxes[1, 1].set_xlabel('City', fontsize=11)\naxes[1, 1].set_ylabel('Price ($)', fontsize=11)\naxes[1, 1].set_title('Price by City', fontweight='bold')\naxes[1, 1].get_figure().suptitle('')  # remove automatic title from boxplot\naxes[1, 1].set_ylim(0, 2_500_000)\n\nplt.tight_layout()\nplt.show()\n```\n\n\n## Link to Streamlit App\n\n[Link to Streamlit app](https://stat386finalproject-seth-carson-4.streamlit.app/)\n\n\n## Analysis\n\n```{python}\n#| message: false\n#| warning: false\n\n# Import necessary modules\nimport itertools\nimport statsmodels.formula.api as smf\nfrom patsy import dmatrices\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression, LassoCV, Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error\n\n# -----------------------------\n# Treat ONLY city and zipcode as categorical\n# -----------------------------\ncat_vars = ['city', 'zipcode']\nfor c in cat_vars:\n    if c in df.columns:\n        df[c] = df[c].astype('category')\n\n# Candidate predictors\ncandidates = [c for c in df.columns if c != 'price']\n\n# -----------------------------\n# Best subsets selection via AIC\n# -----------------------------\nbest_aic = np.inf\nbest_formula = None\nbest_model = None\n\nfor k in range(1, len(candidates) + 1):\n    for subset in itertools.combinations(candidates, k):\n        terms = [f\"C({v})\" if v in cat_vars else v for v in subset]\n        formula = \"price ~ \" + \" + \".join(terms)\n        try:\n            model = smf.ols(formula, data=df).fit()\n            if model.aic < best_aic:\n                best_aic = model.aic\n                best_formula = formula\n                best_model = model\n        except Exception:\n            continue\n\nprint(\"\\n==============================\")\nprint(\"BEST SUBSETS (AIC) MODEL\")\nprint(\"==============================\")\nprint(\"Best AIC:\", best_aic)\nprint(\"Best formula:\", best_formula)\nprint(best_model.summary())\n\n# -----------------------------\n# CV PMSE for Best-AIC model\n# -----------------------------\ny_aic, X_aic = dmatrices(best_formula, data=df, return_type='dataframe')\ny_aic = np.ravel(y_aic)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=1)\nmses_aic = []\n\nfor tr, te in kf.split(X_aic):\n    lr = LinearRegression(fit_intercept=False)\n    lr.fit(X_aic.iloc[tr], y_aic[tr])\n    preds = lr.predict(X_aic.iloc[te])\n    mses_aic.append(mean_squared_error(y_aic[te], preds))\n\npmse_aic = np.mean(mses_aic)\n\n# -----------------------------\n# LASSO (lambda = 1 SE rule)\n# -----------------------------\n# Build full design matrix with dummies\nfull_formula = \"price ~ \" + \" + \".join(\n    [f\"C({v})\" if v in cat_vars else v for v in candidates]\n)\n\ny_lasso, X_lasso = dmatrices(full_formula, data=df, return_type='dataframe')\ny_lasso = np.ravel(y_lasso)\n\n# LASSO with standardization\nlasso_cv = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"lasso\", LassoCV(cv=5, random_state=1))\n])\n\nlasso_cv.fit(X_lasso, y_lasso)\n\n# Lambda_1se\nmse_path = lasso_cv.named_steps[\"lasso\"].mse_path_.mean(axis=1)\nmse_std = lasso_cv.named_steps[\"lasso\"].mse_path_.std(axis=1)\nidx_min = np.argmin(mse_path)\nmse_1se = mse_path[idx_min] + mse_std[idx_min]\nidx_1se = np.where(mse_path <= mse_1se)[0][-1]\n\nalpha_1se = lasso_cv.named_steps[\"lasso\"].alphas_[idx_1se]\n\n# Fit LASSO at lambda_1se\nlasso_1se = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"lasso\", Lasso(alpha=alpha_1se))\n])\n\nlasso_1se.fit(X_lasso, y_lasso)\n\n# Selected variables\ncoef = lasso_1se.named_steps[\"lasso\"].coef_\nselected = X_lasso.columns[coef != 0]\n\nprint(\"\\n==============================\")\nprint(\"LASSO SELECTED VARIABLES (λ_1se)\")\nprint(\"==============================\")\nprint(list(selected))\n\n# -----------------------------\n# Refit OLS using LASSO-selected variables (FIXED)\n# -----------------------------\n\nselected_cols = X_lasso.columns[coef != 0]\n\n# Recover original variable names\nselected_vars = set()\n\nfor col in selected_cols:\n    if col.startswith(\"C(\"):\n        # categorical: extract variable name inside C(...)\n        var = col.split(\"[\")[0]          # C(city)\n        var = var.replace(\"C(\", \"\").replace(\")\", \"\")\n        selected_vars.add(f\"C({var})\")\n    else:\n        selected_vars.add(col)\n\nselected_vars = sorted(selected_vars)\n\nprint(\"\\nVariables used in LASSO refit:\")\nprint(selected_vars)\n\nlasso_formula = \"price ~ \" + \" + \".join(selected_vars)\nlasso_refit = smf.ols(lasso_formula, data=df).fit()\n\nprint(\"\\n==============================\")\nprint(\"OLS REFIT USING LASSO VARIABLES\")\nprint(\"==============================\")\nprint(lasso_refit.summary())\n\n# -----------------------------\n# CV PMSE for LASSO-selected model\n# -----------------------------\ny_lasso2, X_lasso2 = dmatrices(lasso_formula, data=df, return_type='dataframe')\ny_lasso2 = np.ravel(y_lasso2)\n\nmses_lasso = []\nfor tr, te in kf.split(X_lasso2):\n    lr = LinearRegression(fit_intercept=False)\n    lr.fit(X_lasso2.iloc[tr], y_lasso2[tr])\n    preds = lr.predict(X_lasso2.iloc[te])\n    mses_lasso.append(mean_squared_error(y_lasso2[te], preds))\n\npmse_lasso = np.mean(mses_lasso)\n\n# -----------------------------\n# Final comparison\n# -----------------------------\nprint(\"\\n==============================\")\nprint(\"CROSS-VALIDATED PMSE COMPARISON\")\nprint(\"==============================\")\nprint(f\"Best Subsets (AIC) PMSE : {pmse_aic:.3f}\")\nprint(f\"LASSO (1SE) PMSE        : {pmse_lasso:.3f}\")\n```\n\n\n## Conclusion\n\nThe report compares two model-building strategies: exhaustive best-subsets selection using AIC and LASSO (with the 1-SE rule). Fitted model summaries are generated through `statsmodels`, and the models are evaluated using 5-fold cross-validated PMSE. The best‐subsets AIC procedure selected a parsimonious model containing only five structural predictors—beds, baths, square footage, year built, and lot size—yielding an ($R^2$) of 0.577 and the lowest AIC (30231.2) among all candidate models. All included predictors are statistically significant at the $\\alpha=0.05$ level, with square footage and lot size positively associated with price, while the negative coefficient on beds likely reflects multicollinearity with square footage. This model emphasizes interpretability and achieves strong explanatory power with relatively few parameters.\n\nIn contrast, the LASSO model using the one–standard‐error rule selected a much richer specification that included the same core structural variables, added garage size, and incorporated city as a categorical factor, resulting in 26 fitted coefficients in the refit OLS model. This model achieved a slightly higher in‐sample fit ($R^2 = 0.593$), suggesting that location effects explain additional variation in housing prices beyond physical characteristics. However, many individual city coefficients are not statistically significant, indicating that while location matters collectively, its contribution is diffuse across levels rather than driven by a small number of dominant cities.\n\nWhen comparing predictive performance via cross‐validation, the best‐subsets AIC model slightly outperformed the LASSO‐selected model, with a lower PMSE ($2.13 \\times 10^{12}$ vs. $2.22 \\times 10^{12}$). This suggests that the additional complexity introduced by the LASSO model does not translate into improved out‐of‐sample prediction. Overall, the results highlight a classic bias–variance tradeoff: the LASSO model captures more structure through location effects but incurs higher variance, while the simpler AIC‐selected model provides comparable and slightly superior—predictive accuracy with greater interpretability.\n\nThere are several limitations to consider. The scraped dataset may suffer from selection bias, as online listings do not represent all transactions, and measurement errors could exist in features such as square footage or number of bedrooms. Additionally, some predictors are coarse (e.g. `city`) and may obscure spatial heterogeneity. Residual heteroscedasticity and nonlinearity are also possible, suggesting that transforming the price variable (e.g., using $\\log(\\texttt{price})$) or applying robust, heteroscedasticity-consistent standard errors may be appropriate.\n\nFuture work could involve incorporating additional predictors such as year built, lot size, and proximity to amenities, or exploring spatial models that explicitly account for location dependence. Alternative loss functions like MAE could be evaluated, and tree-based ensemble methods such as random forests or gradient boosting could be applied, with comparisons of their calibrated uncertainty against linear models. Finally, the best-performing model could potentially be packaged and deployed via an endpoint or dashboard, enabling users to query price predictions based on property attributes.\n\nFrom a practical standpoint, the results suggest that a sizeable portion of the information needed to predict home prices comes from a small set of basic property features, especially square footage, lot size, and overall layout. It was observed tha adding many location indicators increases model complexity without meaningfully improving predictive accuracy. For real-world use, such as quick price estimates, reporting, or decision support, the simpler AIC-selected model is likely the better choice: it is easier to explain, easier to maintain, and performs just as well (or slightly better) on new data. More complex models may still be useful for deeper analysis of neighborhood effects.","srcMarkdownNoYaml":"\n\n## Introduction\n\nThis project analyzes Utah residential housing listings in several cities in Salt Lake County and Utah counties to explore, build, and evaluate predictive models for house `price`.\n\nThe motivation for this project is to provide data-driven guidance for buyers, sellers, and local planners by identifying key predictors of sale price and producing models that balance predictive accuracy and interpretability.\n\nSome key goals of this project were (1) to produce clear exploratory analyses that reveal relationships between `price` and common housing attributes; (2) to fit defensible regression models (i.e. best-subsets by AIC and a LASSO-regularized model) and compare them using cross-validated PMSE; and (3) to document reproducible code and a small interactive Streamlit app for sharing results.\n\n\n## Data Source and Methodology\n\n1. Data acquisition:\n\n- Raw listings were collected from UtahRealEstate.com with the repository's scraping scripts. The primary ingestion function used in this report is `data_no_scape()` which returns the raw DataFrame used for downstream processing.\n\n2. Cleaning pipeline:\n\n- The cleaning pipeline performs the following steps: removing obvious duplicates, dropping invalid or malformed entries, and standardizing numeric columns (e.g. beds, baths, sqft). For purposes of analysis, we dropped the original `address` and `mls` fields.\n\n3. Analysis workflow:\n\n- Exploratory data analysis involved  visual checks (scatterplots and boxplots) to inspect relationships between `price` and candidate predictors and to assess outliers and heterogeneity across selected cities.\n- Model selection involved exhaustive best-subsets regression evaluated by AIC to identify an interpretable model, and LASSO (with cross-validated penalty) to perform automated variable selection and shrinkage. Models were fit with `statsmodels` and model summaries were constructed with `patsy`.\n- Model assessment: 5-fold cross-validation is used to estimate the predictive mean squared error (PMSE) for competing models.\n\n4. Tooling and reproducibility:\n\n- Primary libraries: `pandas`, `numpy`, `matplotlib`, `seaborn`, `statsmodels`, `patsy`, `scikit-learn`.\n- Project environment and packaging: see `pyproject.toml`\n\n\n## EDA\n\n```{python}\n#| include: false\nimport pandas as pd\nfrom utah_housing_stat386.cleaning import data_no_scape, cleaned_static_data, clean_housing_data, remove_duplicates, remove_invalid_entries\nimport re\n\ndf_raw = data_no_scape()\ndf_clean2 = clean_housing_data(df_raw)\ndf_clean2 = remove_duplicates(df_clean2)\ndf_clean2 = remove_invalid_entries(df_clean2)\ndf = df_clean2.copy()\naddress_list = df['address'].tolist()\npattern = r\"UT \\d{5}\"\nzipcode_list = []\nfor address in address_list:\n    zipcode_list.append(re.search(pattern, address).group()[3:])\ndf['zipcode'] = zipcode_list\ndf = df.drop(columns=['address', 'mls', 'zipcode'])\n```\n```{python}\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Create a 2x2 figure with 4 subplots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfig.suptitle('EDA: Price vs Selected Variables', fontsize=16, fontweight='bold')\n\n# Plot 1 (top-left): Scatterplot - price vs bedrooms (or sqft, year_built, etc.)\naxes[0, 0].scatter(df['beds'], df['price'], alpha=0.5, s=50, color='steelblue')\naxes[0, 0].set_xlabel('Bedrooms', fontsize=11)\naxes[0, 0].set_ylabel('Price ($)', fontsize=11)\naxes[0, 0].set_title('Price vs Bedrooms', fontweight='bold')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_xlim(0, 10)\naxes[0, 0].set_ylim(0, 3_000_000)\n\n# Plot 2 (top-right): Scatterplot - price vs bathrooms (or sqft, lot_size, etc.)\naxes[0, 1].scatter(df['baths'], df['price'], alpha=0.5, s=50, color='coral')\naxes[0, 1].set_xlabel('Bathrooms', fontsize=11)\naxes[0, 1].set_ylabel('Price ($)', fontsize=11)\naxes[0, 1].set_title('Price vs Bathrooms', fontweight='bold')\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xlim(0, 10)\naxes[0, 1].set_ylim(0, 3_000_000)\n\n# Plot 3 (bottom-left): Boxplot - price by garage (categorical)\naxes[1, 0].scatter(df['sqft'], df['price'], alpha=0.5, s=50)\naxes[1, 0].set_xlabel('Square Feet', fontsize=11)\naxes[1, 0].set_ylabel('Price ($)', fontsize=11)\naxes[1, 0].set_title('Price vs Square Footage', fontweight='bold')\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].set_xlim(0, 15_000)\naxes[1, 0].set_ylim(0, 4_000_000)\n\n# Plot 4 (bottom-right): Boxplot - price by city (categorical)\nsub_df = df[df['city'].isin(['lindon', 'orem', 'provo', 'spanish-fork'])]\nsub_df.boxplot(column='price', by='city', ax=axes[1, 1])\naxes[1, 1].set_xlabel('City', fontsize=11)\naxes[1, 1].set_ylabel('Price ($)', fontsize=11)\naxes[1, 1].set_title('Price by City', fontweight='bold')\naxes[1, 1].get_figure().suptitle('')  # remove automatic title from boxplot\naxes[1, 1].set_ylim(0, 2_500_000)\n\nplt.tight_layout()\nplt.show()\n```\n\n\n## Link to Streamlit App\n\n[Link to Streamlit app](https://stat386finalproject-seth-carson-4.streamlit.app/)\n\n\n## Analysis\n\n```{python}\n#| message: false\n#| warning: false\n\n# Import necessary modules\nimport itertools\nimport statsmodels.formula.api as smf\nfrom patsy import dmatrices\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression, LassoCV, Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error\n\n# -----------------------------\n# Treat ONLY city and zipcode as categorical\n# -----------------------------\ncat_vars = ['city', 'zipcode']\nfor c in cat_vars:\n    if c in df.columns:\n        df[c] = df[c].astype('category')\n\n# Candidate predictors\ncandidates = [c for c in df.columns if c != 'price']\n\n# -----------------------------\n# Best subsets selection via AIC\n# -----------------------------\nbest_aic = np.inf\nbest_formula = None\nbest_model = None\n\nfor k in range(1, len(candidates) + 1):\n    for subset in itertools.combinations(candidates, k):\n        terms = [f\"C({v})\" if v in cat_vars else v for v in subset]\n        formula = \"price ~ \" + \" + \".join(terms)\n        try:\n            model = smf.ols(formula, data=df).fit()\n            if model.aic < best_aic:\n                best_aic = model.aic\n                best_formula = formula\n                best_model = model\n        except Exception:\n            continue\n\nprint(\"\\n==============================\")\nprint(\"BEST SUBSETS (AIC) MODEL\")\nprint(\"==============================\")\nprint(\"Best AIC:\", best_aic)\nprint(\"Best formula:\", best_formula)\nprint(best_model.summary())\n\n# -----------------------------\n# CV PMSE for Best-AIC model\n# -----------------------------\ny_aic, X_aic = dmatrices(best_formula, data=df, return_type='dataframe')\ny_aic = np.ravel(y_aic)\n\nkf = KFold(n_splits=5, shuffle=True, random_state=1)\nmses_aic = []\n\nfor tr, te in kf.split(X_aic):\n    lr = LinearRegression(fit_intercept=False)\n    lr.fit(X_aic.iloc[tr], y_aic[tr])\n    preds = lr.predict(X_aic.iloc[te])\n    mses_aic.append(mean_squared_error(y_aic[te], preds))\n\npmse_aic = np.mean(mses_aic)\n\n# -----------------------------\n# LASSO (lambda = 1 SE rule)\n# -----------------------------\n# Build full design matrix with dummies\nfull_formula = \"price ~ \" + \" + \".join(\n    [f\"C({v})\" if v in cat_vars else v for v in candidates]\n)\n\ny_lasso, X_lasso = dmatrices(full_formula, data=df, return_type='dataframe')\ny_lasso = np.ravel(y_lasso)\n\n# LASSO with standardization\nlasso_cv = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"lasso\", LassoCV(cv=5, random_state=1))\n])\n\nlasso_cv.fit(X_lasso, y_lasso)\n\n# Lambda_1se\nmse_path = lasso_cv.named_steps[\"lasso\"].mse_path_.mean(axis=1)\nmse_std = lasso_cv.named_steps[\"lasso\"].mse_path_.std(axis=1)\nidx_min = np.argmin(mse_path)\nmse_1se = mse_path[idx_min] + mse_std[idx_min]\nidx_1se = np.where(mse_path <= mse_1se)[0][-1]\n\nalpha_1se = lasso_cv.named_steps[\"lasso\"].alphas_[idx_1se]\n\n# Fit LASSO at lambda_1se\nlasso_1se = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"lasso\", Lasso(alpha=alpha_1se))\n])\n\nlasso_1se.fit(X_lasso, y_lasso)\n\n# Selected variables\ncoef = lasso_1se.named_steps[\"lasso\"].coef_\nselected = X_lasso.columns[coef != 0]\n\nprint(\"\\n==============================\")\nprint(\"LASSO SELECTED VARIABLES (λ_1se)\")\nprint(\"==============================\")\nprint(list(selected))\n\n# -----------------------------\n# Refit OLS using LASSO-selected variables (FIXED)\n# -----------------------------\n\nselected_cols = X_lasso.columns[coef != 0]\n\n# Recover original variable names\nselected_vars = set()\n\nfor col in selected_cols:\n    if col.startswith(\"C(\"):\n        # categorical: extract variable name inside C(...)\n        var = col.split(\"[\")[0]          # C(city)\n        var = var.replace(\"C(\", \"\").replace(\")\", \"\")\n        selected_vars.add(f\"C({var})\")\n    else:\n        selected_vars.add(col)\n\nselected_vars = sorted(selected_vars)\n\nprint(\"\\nVariables used in LASSO refit:\")\nprint(selected_vars)\n\nlasso_formula = \"price ~ \" + \" + \".join(selected_vars)\nlasso_refit = smf.ols(lasso_formula, data=df).fit()\n\nprint(\"\\n==============================\")\nprint(\"OLS REFIT USING LASSO VARIABLES\")\nprint(\"==============================\")\nprint(lasso_refit.summary())\n\n# -----------------------------\n# CV PMSE for LASSO-selected model\n# -----------------------------\ny_lasso2, X_lasso2 = dmatrices(lasso_formula, data=df, return_type='dataframe')\ny_lasso2 = np.ravel(y_lasso2)\n\nmses_lasso = []\nfor tr, te in kf.split(X_lasso2):\n    lr = LinearRegression(fit_intercept=False)\n    lr.fit(X_lasso2.iloc[tr], y_lasso2[tr])\n    preds = lr.predict(X_lasso2.iloc[te])\n    mses_lasso.append(mean_squared_error(y_lasso2[te], preds))\n\npmse_lasso = np.mean(mses_lasso)\n\n# -----------------------------\n# Final comparison\n# -----------------------------\nprint(\"\\n==============================\")\nprint(\"CROSS-VALIDATED PMSE COMPARISON\")\nprint(\"==============================\")\nprint(f\"Best Subsets (AIC) PMSE : {pmse_aic:.3f}\")\nprint(f\"LASSO (1SE) PMSE        : {pmse_lasso:.3f}\")\n```\n\n\n## Conclusion\n\nThe report compares two model-building strategies: exhaustive best-subsets selection using AIC and LASSO (with the 1-SE rule). Fitted model summaries are generated through `statsmodels`, and the models are evaluated using 5-fold cross-validated PMSE. The best‐subsets AIC procedure selected a parsimonious model containing only five structural predictors—beds, baths, square footage, year built, and lot size—yielding an ($R^2$) of 0.577 and the lowest AIC (30231.2) among all candidate models. All included predictors are statistically significant at the $\\alpha=0.05$ level, with square footage and lot size positively associated with price, while the negative coefficient on beds likely reflects multicollinearity with square footage. This model emphasizes interpretability and achieves strong explanatory power with relatively few parameters.\n\nIn contrast, the LASSO model using the one–standard‐error rule selected a much richer specification that included the same core structural variables, added garage size, and incorporated city as a categorical factor, resulting in 26 fitted coefficients in the refit OLS model. This model achieved a slightly higher in‐sample fit ($R^2 = 0.593$), suggesting that location effects explain additional variation in housing prices beyond physical characteristics. However, many individual city coefficients are not statistically significant, indicating that while location matters collectively, its contribution is diffuse across levels rather than driven by a small number of dominant cities.\n\nWhen comparing predictive performance via cross‐validation, the best‐subsets AIC model slightly outperformed the LASSO‐selected model, with a lower PMSE ($2.13 \\times 10^{12}$ vs. $2.22 \\times 10^{12}$). This suggests that the additional complexity introduced by the LASSO model does not translate into improved out‐of‐sample prediction. Overall, the results highlight a classic bias–variance tradeoff: the LASSO model captures more structure through location effects but incurs higher variance, while the simpler AIC‐selected model provides comparable and slightly superior—predictive accuracy with greater interpretability.\n\nThere are several limitations to consider. The scraped dataset may suffer from selection bias, as online listings do not represent all transactions, and measurement errors could exist in features such as square footage or number of bedrooms. Additionally, some predictors are coarse (e.g. `city`) and may obscure spatial heterogeneity. Residual heteroscedasticity and nonlinearity are also possible, suggesting that transforming the price variable (e.g., using $\\log(\\texttt{price})$) or applying robust, heteroscedasticity-consistent standard errors may be appropriate.\n\nFuture work could involve incorporating additional predictors such as year built, lot size, and proximity to amenities, or exploring spatial models that explicitly account for location dependence. Alternative loss functions like MAE could be evaluated, and tree-based ensemble methods such as random forests or gradient boosting could be applied, with comparisons of their calibrated uncertainty against linear models. Finally, the best-performing model could potentially be packaged and deployed via an endpoint or dashboard, enabling users to query price predictions based on property attributes.\n\nFrom a practical standpoint, the results suggest that a sizeable portion of the information needed to predict home prices comes from a small set of basic property features, especially square footage, lot size, and overall layout. It was observed tha adding many location indicators increases model complexity without meaningfully improving predictive accuracy. For real-world use, such as quick price estimates, reporting, or decision support, the simpler AIC-selected model is likely the better choice: it is easier to explain, easier to maintain, and performs just as well (or slightly better) on new data. More complex models may still be useful for deeper analysis of neighborhood effects."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"css":["styles.css"],"output-file":"TechnicalReport.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","python":{"path":".venv/bin/python"},"theme":"cosmo","title":"Technical Report","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}